{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\mminbay\\\\Documents\\\\bait_research')\n",
    "# from fasta_utils import sequences_from_fasta, sequences_to_fasta\n",
    "# from utils import hamming_distance\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from wfc_csp import wfc_csp, generate_randomized_strings\n",
    "import random\n",
    "from testing import get_test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [file for file in os.listdir('/home/mminbay/honors_thesis/sequence_data/synthesized/') if '.fasta' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_info(files[0])['pccov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jkam'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'joe'.replace('oe', 'k' + 'a' + 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution for 10 strings found in 0.0054280757904052734. Max distance = 32\n",
      "Solution for 10 strings found in 0.005285739898681641. Max distance = 31\n",
      "Solution for 10 strings found in 0.0052225589752197266. Max distance = 33\n",
      "Solution for 100 strings found in 0.00748443603515625. Max distance = 35\n",
      "Solution for 100 strings found in 0.0074198246002197266. Max distance = 37\n",
      "Solution for 100 strings found in 0.00789332389831543. Max distance = 36\n",
      "Solution for 1000 strings found in 0.03404378890991211. Max distance = 37\n",
      "Solution for 1000 strings found in 0.0334780216217041. Max distance = 38\n",
      "Solution for 1000 strings found in 0.03412961959838867. Max distance = 38\n",
      "Solution for 10000 strings found in 0.29258203506469727. Max distance = 38\n",
      "Solution for 10000 strings found in 0.2939329147338867. Max distance = 38\n",
      "Solution for 10000 strings found in 0.2928659915924072. Max distance = 39\n",
      "Solution for 100000 strings found in 2.92562198638916. Max distance = 40\n",
      "Solution for 100000 strings found in 2.8790040016174316. Max distance = 40\n",
      "Solution for 100000 strings found in 2.9220056533813477. Max distance = 40\n"
     ]
    }
   ],
   "source": [
    "d = 40\n",
    "ALPHABET = ['A', 'G', 'T', 'C']\n",
    "l = 120\n",
    "for k in [10, 100, 1000, 10000, 100000]:\n",
    "    for i in range(3):\n",
    "        solution = ''.join(random.choice(ALPHABET) for _ in range(l))\n",
    "        strings = generate_randomized_strings(solution, k, d)\n",
    "        start = time.time()\n",
    "        s, dist = wfc_csp(strings, ['A', 'G', 'C', 'T'], d)\n",
    "        end = time.time()\n",
    "        print('Solution for {} strings found in {}. Max distance = {}'.format(k, end - start, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "SEQUENCES_DIR: str = 'C:\\\\Users\\\\mminbay\\\\Documents\\\\bait_research\\\\test_data'\n",
    "CLUSTERS_DIR: str = 'C:\\\\Users\\\\mminbay\\\\Documents\\\\bait_research\\\\clusters'\n",
    "OUTPUTS_DIR: str = 'C:\\\\Users\\\\mminbay\\\\Documents\\\\bait_research\\\\outputs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_report(report_path: str):\n",
    "    stupid_alignments = {}\n",
    "    last_num = r\"[0-9]+\\.$\"\n",
    "    with open(report_path, 'r') as file:\n",
    "        line = file.readline()\n",
    "        while line:\n",
    "            line = line.strip()\n",
    "            if 'Identifier' in line:\n",
    "                for i in range(2):\n",
    "                    line = file.readline() # skip 2 lines \n",
    "                line = line.strip()\n",
    "                rep = int(re.search(last_num, line).group()[:-1])\n",
    "                for i in range(6):\n",
    "                    line = file.readline() # skip 6\n",
    "                line = line.strip()[1:-1]\n",
    "                items = line.split(', ')\n",
    "                items = [int(x) for x in items]\n",
    "                stupid_alignments[rep] = items\n",
    "            line = file.readline()\n",
    "    return stupid_alignments  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_decide(str1, str2, m):\n",
    "    '''\n",
    "    '''\n",
    "    distance = 0\n",
    "    for i in range(len(str1)):\n",
    "        if str1[i] == 'N': # character N does not match with anything\n",
    "            distance += 1 \n",
    "        elif str1[i] != str2[i]:\n",
    "            distance += 1\n",
    "        if distance > m:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences read:  1\n",
      "Total length:  100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mminbay\\AppData\\Local\\anaconda3\\envs\\bait_research\\lib\\site-packages\\pydivsufsort\\divsufsort.py:75: UserWarning: converting str argument uses more memory\n",
      "  warnings.warn(\"converting str argument uses more memory\")\n"
     ]
    }
   ],
   "source": [
    "# SETUP BLOCK\n",
    "sequence_name = 'megares_100k_sequences.fasta'\n",
    "_, seq = sequences_from_fasta(os.path.join(SEQUENCES_DIR, sequence_name))\n",
    "seqlens = [len(x) for x in seq]\n",
    "seq = ''.join(seq)\n",
    "seq = seq.upper()\n",
    "sa = divsufsort(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_and_extend(\n",
    "    seq: str,\n",
    "    bait: str,\n",
    "    m: int,\n",
    "    sa = None,\n",
    "    seed_len: int = 10,\n",
    "    seqlens = None,\n",
    "):\n",
    "    '''\n",
    "    Applies the seed-and-extend heuristic to search for imperfect matches of the bait\n",
    "    in the sequence. Returns a list of indices of the matches.\n",
    "\n",
    "    Arguments:\n",
    "        seq (str): Sequence to search for the baits in. \n",
    "        bait (str): Bait to search for.\n",
    "        m (int): Allowed Hamming distance for each match.\n",
    "        sa (suffix array): Suffix array of the string. If not provided, will be constructed.\n",
    "        seed_len (int): Seed length to use for the heuristic. Every seed-length substring of the \n",
    "            bait will be used as seeds.\n",
    "        seqlens (list[int]): If `seq` was obtained by concatenating sequences, this list \n",
    "            should have the lengths of each individual sequence before concatenation. This \n",
    "            is because baits should not be able to align around the concatenation points, so\n",
    "            these values will be used to eliminate those baits.\n",
    "    '''\n",
    "    if sa is None:\n",
    "        checkpoint = time.time()\n",
    "        sa = divsufsort(seq)\n",
    "        print('Divsufsort took {} seconds.'.format(time.time() - checkpoint))\n",
    "    if seqlens is None:\n",
    "        seqlens = [len(seq)]\n",
    "\n",
    "    lb = len(bait)\n",
    "    if seed_len > lb:\n",
    "        raise Exception('Specified seed length is larger than the actual bait.')\n",
    "    \n",
    "    final_matches = set()\n",
    "    checked_indices = set()\n",
    "\n",
    "    lookup_time = 0\n",
    "    discard_time = 0\n",
    "    alignment_time = 0\n",
    "    d_picked = 0\n",
    "    d_checked = 0\n",
    "    d_concat = 0\n",
    "    d_negative = 0\n",
    "    \n",
    "    # for i in tqdm(range(lb - seed_len + 1), desc = 'Considering seeds', unit = 'seed'):\n",
    "    for i in range(lb - seed_len + 1):\n",
    "        checkpoint = time.time()\n",
    "        seed = bait[i: i + seed_len]\n",
    "        seed_matches = sa_search(seq, sa, seed)\n",
    "        lookup_time += time.time() - checkpoint\n",
    "        if seed_matches[1] is None:\n",
    "            continue\n",
    "        seed_matches = set(sa[seed_matches[1]: seed_matches[0] + seed_matches[1]])\n",
    "        checkpoint = time.time()\n",
    "        sum_seqlens = 0\n",
    "        for seqlen in seqlens:\n",
    "            discard_matches = set()\n",
    "            sum_seqlens += seqlen\n",
    "            for match in seed_matches:\n",
    "                # find actual start of this alignment and check if it covers a concatenation\n",
    "                actual_start = match - i\n",
    "                if actual_start in final_matches: # if we already checked the coverage\n",
    "                    discard_matches.add(match)     \n",
    "                    d_picked += 1\n",
    "                elif actual_start in checked_indices:\n",
    "                    discard_matches.add(match)\n",
    "                    d_checked += 1\n",
    "                elif actual_start < 0:\n",
    "                    discard_matches.add(match)\n",
    "                    d_negative += 1\n",
    "                elif actual_start < sum_seqlens and actual_start > sum_seqlens - lb:\n",
    "                    discard_matches.add(match)\n",
    "                    d_concat += 1\n",
    "                checked_indices.add(actual_start)\n",
    "            seed_matches = seed_matches.difference(discard_matches) # VERY INEFFICIENT - change\n",
    "        discard_time += time.time() - checkpoint\n",
    "        checkpoint = time.time()\n",
    "        for match in seed_matches:\n",
    "            actual_start = match - i\n",
    "            sub = seq[actual_start: actual_start + lb]\n",
    "            if len(sub) != len(bait):\n",
    "                print(actual_start, 'wtf happened here')\n",
    "            if hamming_decide(bait, sub, m):\n",
    "                final_matches.add(actual_start)\n",
    "        alignment_time += time.time() - checkpoint\n",
    "    # print('Lookup time:', lookup_time)\n",
    "    # print('Discard time:', discard_time)\n",
    "    # print('Alignment time:', alignment_time)\n",
    "    # print('Discarded because picked:', d_picked)\n",
    "    # print('Discarded because checked:', d_checked)\n",
    "    # print('Discarded because negative:', d_negative)\n",
    "    # print('Discarded because concat:', d_concat)\n",
    "    # print('Found alignments:', len(final_matches))\n",
    "    return final_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences read:  347\n",
      "Total length:  41640\n"
     ]
    }
   ],
   "source": [
    "_, baits = sequences_from_fasta(os.path.join(OUTPUTS_DIR, 'megares_100k_sequences_catch.fasta'))\n",
    "stupid_alignments = read_report(os.path.join(OUTPUTS_DIR, 'megares_100k_comparison.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mminbay\\AppData\\Local\\anaconda3\\envs\\bait_research\\lib\\site-packages\\pydivsufsort\\divsufsort.py:75: UserWarning: converting str argument uses more memory\n",
      "  warnings.warn(\"converting str argument uses more memory\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "non_exact = 0\n",
    "no_align = 0\n",
    "missed = 0\n",
    "for bait in baits:\n",
    "    bait = bait.upper()\n",
    "    search_res = sa_search(seq, sa, bait)\n",
    "    occurence = search_res[1]\n",
    "\n",
    "    in_sa = sa[occurence]\n",
    "    results = seed_and_extend(\n",
    "        seq,\n",
    "        bait,\n",
    "        40,\n",
    "        sa,\n",
    "        seed_len = 20,\n",
    "        seqlens = seqlens\n",
    "    )\n",
    "    if in_sa not in stupid_alignments.keys():\n",
    "        no_align += 1\n",
    "        continue\n",
    "    stupid = set(stupid_alignments[in_sa])\n",
    "    if stupid != results:\n",
    "        # print(in_sa)\n",
    "        # print(stupid)\n",
    "        # print(results)\n",
    "        non_exact += 1\n",
    "        missed += len(stupid.difference(results))\n",
    "print(non_exact)\n",
    "print(no_align)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "print(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated the following base repeats:\n",
      "['GCATCTCATCATTGTGGCCTTTCAAACCGGGCACGTACCCAAGTTTTGCTGACGTAATACTAGTGACCCCTACATTATCTATCATGGCTTGGCGGTCGAG', 'TCCGCGCGCAATACGCCTTAGTCCGTGTGGTAAGAGATTACATAGTTTCCGGGCCAGCAGACAAGTGATCGTATAGTATTAGCATATGGCGCGTGTCATA', 'TGCTCTTTGACTGCGCGCGATATAATCTGTTACTCGACCGCGCTTTTACGAAGTATGGAAGATGCAGGGCCTACATGCCACGTTTGAAAACGTACAATCA']\n",
      "Index 881 has been populated with the following:\n",
      "GCATCTCATCATTATGGCCTTTCAAACCGGGCACGTACCCAAGTTTTGCTGACGTAATACTAGTGACCCCTACATTATTTATCATGGCTTGGCGGGCGAG\n",
      "Index 152 has been populated with the following:\n",
      "GCATCTCATCACTGTGGCCATTCAAACCAGGCACGTACCCAAGTTTTGCTGACGTAATACTAGTGACCCCTACATTATCTATCATGGCTTGGCGGTCGAG\n",
      "Index 772 has been populated with the following:\n",
      "GCATCTCATTATTATGGCCTTTCAAACCGGGCACGTACCCAAGTTTTTCTGACGTAATACTAGTGACCCCTACATTATCTATCATGGCTTGGCGGTCGAG\n",
      "Index 12 has been populated with the following:\n",
      "GCATCTCATCATTGTGGCCTTTCAAACCGGGCACGTACCCAAGTTTTGCTGACGTAATACTAGAGACCCCTACATTATCTATCATGGCTTGGCGGTCGAA\n",
      "Index 693 has been populated with the following:\n",
      "TCCGAGCGTAATACGCCTTAGTCCGTGTGGTAAGAGATTACATAGTTTCCGGGCCAGCAGACAAGTGATCGTACAGTATTAGCATATGGCGCGTGGCATA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'GTCACTTAAATAGCATCTCATCATTGTGGCCTTTCAAACCGGGCACGTACCCAAGTTTTGCTGACGTAATACTAGAGACCCCTACATTATCTATCATGGCTTGGCGGTCGAAGGAGCTCGTTTTACAGTAAGCAACGGACTTGTCCACGAGCGCATCTCATCACTGTGGCCATTCAAACCAGGCACGTACCCAAGTTTTGCTGACGTAATACTAGTGACCCCTACATTATCTATCATGGCTTGGCGGTCGAGGGCAGTACAGCTTCTCTATAGTAAACGACTACCCGCACTTTTTCAGGCCTTTCGGAATATATTGAGAGAGGATGGATAATTTACCCCTAATGGGATTTTGCCACCCGCGGGGTATCCCTTCGCAAGGAATACCGTGGCCGCCACCCATTACGTGGTAATCCGAACAGTGACGCCGACTTGATGATATGCGCGGGTACGGACCGGGGGTATGGTCCCGCACAGACACCAAAGATTCCTTCAATTGAGGGCTGTCCGGAGCGGAGTATCGCATGCGCACAGCCGCTGGGACTACTCAAACTGTACGGGCATATTGAAAGACCTCAATTACTCCCCTCAGGAAAATAGGGTAGGTGCGCTAAATTTATAAGAGTGACGCATTGGCCTCGAACCGTGTTGCCTAGTTTAATAGGCAAATGCGGATCGTCAGTTCCCAGCAAGGGTTCCGAGCGTAATACGCCTTAGTCCGTGTGGTAAGAGATTACATAGTTTCCGGGCCAGCAGACAAGTGATCGTACAGTATTAGCATATGGCGCGTGGCATATCAAACCGGGCACGTACCCAAGTTTTTCTGACGTAATACTAGTGACCCCTACATTATCTATCATGGCTTGGCGGTCGAGGATGAAAAAGCATCTCATCATTATGGCCTTTCAAACCGGGCACGTACCCAAGTTTTGCTGACGTAATACTAGTGACCCCTACATTATTTATCATGGCTTGGCGGGCGAGTGGTCATCGTGAGTTTCTC'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesize_sequence(\n",
    "    1000,\n",
    "    3,\n",
    "    (100, 100),\n",
    "    0.5,\n",
    "    5,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 4\n",
    "m = 1\n",
    "seq = 'AACTGGAGGTACCTGGAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "baits = [seq[i:i +l] for i in range(len(seq) - l + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(str1, str2):\n",
    "    # Check if the strings are of equal length\n",
    "    if len(str1) != len(str2):\n",
    "        raise ValueError(\"Input strings must be of equal length\")\n",
    "\n",
    "    # Calculate Hamming distance\n",
    "    distance = sum(c1 != c2 for c1, c2 in zip(str1, str2))\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverages = {}\n",
    "for bait in baits:\n",
    "    covered_indices = []\n",
    "    for i in range(len(seq) - l + 1):\n",
    "        snippet = seq[i: i + l]\n",
    "        if hamming_distance(snippet, bait) <= m:\n",
    "            covered_indices.append(i)\n",
    "    coverages[bait] = covered_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AACT': [0, 10],\n",
       " 'ACTG': [1, 11],\n",
       " 'CTGG': [2, 12],\n",
       " 'TGGA': [3, 13],\n",
       " 'GGAG': [4, 14],\n",
       " 'GAGG': [5],\n",
       " 'AGGT': [6],\n",
       " 'GGTA': [7],\n",
       " 'GTAC': [8],\n",
       " 'TACC': [9],\n",
       " 'ACCT': [0, 10],\n",
       " 'CCTG': [1, 11]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "coli3 = [file for file in os.listdir('/home/mminbay/honors_thesis/outputs/megares/') if 'fasta' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coli3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
